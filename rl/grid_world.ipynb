{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from envs.discrete_MDP import DiscreteMDP\n",
    "from policy_iteration import DiscretePolicy, policy_evaluation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# creating 4x4 gridworld\n",
    "# actions: 0 - up, 1 - right, 2 - down, 3 - left\n",
    "\n",
    "p0 = np.ones(16) / 16\n",
    "p = np.zeros([16, 16, 4]) # 0 and 16 terminal states\n",
    "for s in range(1, 15):\n",
    "    if s - 4 < 0:\n",
    "        p[s, s, 0] = 1\n",
    "    else:\n",
    "        p[s - 4, s, 0] = 1\n",
    "\n",
    "    if s % 4 == 3:\n",
    "        p[s, s, 1] = 1\n",
    "    else:\n",
    "        p[s + 1, s, 1] = 1\n",
    "\n",
    "    if s + 4 > 15:\n",
    "        p[s, s, 2] = 1\n",
    "    else:\n",
    "        p[s + 4, s, 2] = 1\n",
    "\n",
    "    if s % 4 == 0:\n",
    "        p[s, s, 3] = 1\n",
    "    else:\n",
    "        p[s - 1, s, 3] = 1\n",
    "\n",
    "r = -np.ones([16, 16, 4]) # -1 for all transitions\n",
    "\n",
    "grid_env = DiscreteMDP(p0, p, r)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., 1.],\n       [1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[:, 1, :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# create policy\n",
    "policy = DiscretePolicy(grid_env)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([  0., -14., -20., -22., -14., -18., -20., -20., -20., -20., -18.,\n       -14., -22., -20., -14.,   0.])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_evaluation(policy, grid_env, 0.001).round(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
